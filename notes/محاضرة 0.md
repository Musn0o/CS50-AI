##  الذكاء الاصطناعي
---

الذكاء الاصطناعي يشمل عدة تقنيات التي التي تحاكي السلوك الذكي على سبيل المثال يمكن للذكاء الاصطناعي انا يحدد الوجوه بالصور على وسائل التواصل الاجتماعي والتغلب على بطل العالم في الشطرنج ومعالجة كلامك عندما تتحدث الى  (Siri) او (Alexa) على هاتفك

في هذا الكورس سنقوم بدراسة بعض الافكار التي تجعل الذكاء الاصطناعي ممكناَ:

0. **البحث (Search)**

إيجاد حل لمشكلة مثل تطبيق الخريطة او التوصيل الذي يقوم بالبحث عن أفضل طريق من مكانك الى الوجهة أو مثل لعب لعبة والقدرة على تحديد الخطوة التالية.

1. **المعرفة (Knowledge)**

تقديم المعلومات بطريقة نستطيع إستخراج إستدلالات منها.

2. **عدم التأكد (Uncertainty)**

التعامل مع الاحداث الغير مؤكدة باستخدام الاحتمالات.

3. **التحسين (Optimization)**

عدم الاكتفاء بالعثور على طريقة واحدة في حل مشكلة بل الأحسن أو أفضل طريقة حل ممكنة

4. **التعلم (Learning)**

تطوير الأداء عن طريق الحصول على بيانات و خبرات على سبيل المثال البريد الإلكتروني الخاص بك يمكنه تحديد الرسائل الزائفة من الحقيقية بناءاََ على الخبرات السابقة.

5. **الشبكات العصبية (Neural Networks)**

بنية البرنامج مستوحاة من العقل البشري ليستطيع القيام بالمهام بشكل فعال.

6. **اللغة (Language)**

معالجة وفهم اللغة الطبيعية (البشرية) التي ينتجها ويفهمها البشر


## البحث (Search)
---
تتضمن **مشكلات البحث** عاملاً (أو وكيلاً) يُعطى حالة أولية وحالة هدف، ويُرجع هذا الوكيل حلاً يوضح كيفية الانتقال من الحالة الأولى إلى الحالة الثانية (الهدف). تستخدم **تطبيقات الملاحة والتوصيل** عملية بحث نموذجية، حيث يستقبل الوكيل (الجزء المسؤول عن التفكير في البرنامج) موقعك الحالي والوجهة المطلوبة كمدخلات، وبناءً على **خوارزمية بحث**، يُرجع مساراً مقترحاً. ومع ذلك، هناك أشكال عديدة أخرى لمشكلات البحث، مثل الألغاز والمتاهات.

**بالمصري الدارج كده، الموضوع عامل زي لما تكون رايح تزور قرايبك في مكان عمرك ما روحتوا قبل كده. أنت عارف أنت فين دلوقتي (حالة البداية) وعارف عايز تروح فين (حالة الهدف). المهمة بقى إنك تلاقي أسهل طريق أو أسرع طريق يوصلك هناك. ده بالظبط اللي الـ"بحث" بيحاول يعمله في عالم الذكاء الاصطناعي!**

![15 puzzle](https://cs50.harvard.edu/ai/notes/0/15puzzle.png)

إيجاد حل للغز مكون من 15 قطعة سيتطلب إستخدام خوارزمية البحث

- **الوكيل (Agent)**

هو كيان **يدرك** بيئته **و يتصرف بناءً عليها**. في تطبيق الملاحة على سبيل المثال سوف يمثل الوكيل سيارة تحتاج الى اختيار التحركات المطلوب اتخاذها للوصول للهدف المراد.

-  **الحالة (State)**

هي وضع او موقع الوكيل في البيئة الخاصة به على سبيل المثال في اللغز المكون من 15 قطعة الحالة تمثل الشكل الذي ترى به ترتيب القطع بشكل معين عند تحريك قطعة واحدة يتم التغيير الى **حالة جديدة**

-  **الحالة الأولية (Initial State)**

الحالة التي تبدأ خوارزمية البحث عندها في برنامج الملاحة سيكون هذا مكانك الحالي.

-  **التحركات (Actions)**

الخيارات التي يمكن اتخاذها في حالة معينة بتعبير أدق يمكن معاملتها **كدالة (function)** تأخذ معطيات و تمنحك نتائج عندما تقوم بأخذ الحالة `s` كمعطى `Actions(s)` تمنحك مجموعة من التحركات التي يمكن اتخاذها في الحالة التي نقف بها `s` . على سبيل المثال في اللغز المكون من 15 قطعة الخيارات المتاحة للحالة تكون الطرق التي يمكنك تحريك القطع حسب الشكل الحالي (4 اذا كان الفراغ بالمنتصف, 3 اذا كان بالجانب او 2 اذا كان بالكورنر)

-  **نموذج الانتقال (Transition Model)**

وصف لشكل الحالة الذي سينتج من اتخاذ اي خيار ملائم في أي حالة. بتعبير أدق يمكن اعتبارها **كدالة (function)** عندما تأخذ الحالة `s` و الخيار  `a` كمعطيات يكون  `النتائج (s, a)` هذه هي الحالة الناتجة من اتخاذ الخيار `a` مع الحالة `s` .  على سبيل المثال في اللغز المكون من 15 قطعة الهيكل الحالي (الحالة `s`) اذا قمت بتحريك قطعة الى أي اتجاه (الحركة `a`) ستصل الى شكل جديد من اللغز (حالة جديدة)

-  **نطاق الحالات**

هو مجموعة الحالات الممكنة التي يمكن الوصول إليها انطلاقًا من الحالة الابتدائية من خلال أي تسلسل من الأختيارات. فعلى سبيل المثال، في لغز 15، يتكوّن نطاق الحالات من جميع الترتيبات الممكنة على اللوحة والبالغ عددها ‎16!⁄2‎، والتي يمكن الوصول إليها من أي حالة ابتدائية. يمكن تصوّر نطاق الحالات كأنه رسم بياني موجه، تمثّل فيه الحالات كمحطات، والاختيارات كطرق تصل بين المحطات.

**ملاحظة:**  
العدد ‎16!⁄2‎ يمثل جميع الترتيبات الممكنة لقطع لغز 15 (بما في ذلك الفراغ) التي يمكن الوصول إليها فعليًا من خلال تحريك القطع. رغم أن هناك ‎16!‎ ترتيبًا إجماليًا، فإن نصفها فقط يمكن حله بسبب قيود رياضية تتعلق بطريقة حركة القطع، لذلك نقسم على 2.


![State Space](https://cs50.harvard.edu/ai/notes/0/statespace.png)

-  **اختبار الهدف (Goal Test)**

هي الطريقة التي تحدد اذا كانت الحالة المعطاة هي الهدف او لا. على سبيل المثال في ابليكيشن التوصيل اختبار الهدف سيكون اما الموقع الحالي للوكيل (السيارة) في المكان المراد الوصول اليه ويكون تم حل المشكلة او تستمر عملية البحث.

-  **تكلفة الطريق (Path Cost)**

التكلفة المرتبطة بكل طريق من الممكن ان تأخذه. على سبيل المثال ابليكيشن التوصيل يقوم بحساب اقصر طريق بحيث يكون غير مكلف وولإيجاد أسرع طريق ممكن للوصول إلى الهدف

## حل مشكلات البحث
---

-  **الحل (Solution)**

هو تسلسل من الاختيارات التي تنقلنا من الحالة الأولية إلى الحالة الهدف.

يعني لو الجو حر عندك زيي **الحل** غالباََ انك تشوف عربية توصلك من بيتك للبحر.

-  **الحل الأمثل (Optimal Solution)**

هو الحل ذو التكلفة الأقل من بين جميع الحلول الممكنة (غير مكلف من ناحية المسافة)


في عملية البحث يتم تخزين البيانات غالباََ في **المحطة (node)** وهو يحتوي على البيانات التالية:

- حالة
- المحطة السابقة (الأم) المتسببة في وجود المحطة الحالية
- الخيار الذي تم تطبيقة على الأم للوصول للمحطة الحالية
- التكلفة من الحالة الأولية الى المحطة الحالية
---
**ملاحظة:**

المصطلح العلمي الشائع ل **(node)** هو **عقدة** ولكن انا لا أهتم للمصطلحات العلمية المعقدة الي يهمني هو ايصال المعلومة و أفضل استخدام **المحطة** لتبسيط الأمور لأنها مفهومه أكثر عندما نتحدث عن البحث عن مكان او شئ في العموم لكن" **عقدة؟**" احنا مش جايين نسوق سفينة ولا جايين نحط العقدة في المنشار هدفي ان انا اخلي الكلام بسيط ومفهوم لكل الناس بقدر الإمكان.

---
المحطات تحتوي على معلومات التي تجعلها مهمه جدا في خوارزمية البحث. المحطات تحتوي على **الحالة** التي يمكن فحصها عن طريق عمل **اختبار للهدف (goal test)** لمعرفة اذا كانت هي اخر حالة نريد الوصول اليها. اذا كانت هي الحالة المراده يتم حساب تكلفة الطريق لنقطة للمحطة الحالية لمقارنتها بالمحطات الأخرى. وهذا سيساعدنا في اختيار **الحل الأمثل (Optimal Solution)**. عند اختيار محطة معينة بفضل تخزين **المحطة السابقة (الأم)** و **الخيار (action)** الذي تم اتخاذه من الأم للمحطة الحالية من الممكن العودة الى الخلف خطوة بخطوة حتى **حالة البداية (initial state)** وهذا التسلسل من الخيارات هو **الحل (solution)**

و مع ذلك المحطات ببساطة هيكل من البيانات لا تقوم بالبحث وانما تحتفظ بالمعلومات. لنقوم بالبحث الفعلي نقوم بإستخدام **السائق (the frontier)** وهو المسئول عن إدارة المحطات. عند بداية عمل السائق يكون لدية الحالة الأولى و **مجموعة المحطات المستكشفة (set of explored items)** وسيقوم بتكرار الاختيارات التالية حتى يصل الى **الحل**.

تكرار:

1. اذا كان السائق ليس لدية أي طرق أخرى ليستكشفها
	
	-  توقف لا يوجد طريقة حل للمشكلة

2. تقوم بإزالة محطة من قائمة السائق وهذه المحطة سيتم اخذها بالإعتبار

3. اذا كانت المحطة تحتوي على الحالة المراد الوصول اليها

	-  هذا هو الحل توقف
	او
	- قم بالتوسع عن طريق (إيجاد كل المحطات الجديدة التي يمكن الوصول إليها من المحطة الحالية), وقم بإضافة المحطات الناتجة الى قائمة السائق
	-  قم بإضافة المحطة الحالية  ل **مجموعة المحطات المستكشفة (set of explored items)** 

---
**ملاحظة:**

انا عارف طبعاََ ان **(the frontier)** معناها الصحيح **(الحدود)** ولو بشكل علمي ممكن يكون **(حدود البحث)** بس مش ناقصة تعقيدات والله الجو حر ومش مستحملة مصطلحات مجعلصة خلي الدنيا ايزي و
**(سواق)** هيوصلك من هنا لهنا وخلصت يعني مغلطناش ف البخاري

---

فكك بقى من الكلام دا وخليك معايا انا عاوز اروح البحر كل يوم لأن الجو حر فيه. 3 شواطئ معروفة بس مش عارف ايه أقرب واحد ليا انا في **محرم بك نقطة البداية (initial state)** و **هدفي هو الشاطئ (goal state)**  انا هركب تاكسي واقول **للسواق (the frontier)** انهاردا نطلع على أول شاطئ وقبل ما أوصل الشاطئ اشوف **المحطة (node)** الى قبله علشان اقدر احدد مسافتها من  **محرم بك نقطة البداية** و **السواق** هيكرر معايا نفس السيناريو بشكل يومي لحد ما نوصل لأقرب شاطئ.

طيب افرض **السواق (frontier)** على الله حكايته وميعرفش الطريق؟ هنضطر نستكشف بقى **المحطات (nodes)** كلها يا معلم مع **السواق (frontier)** دا ورزقي ورزقك ع الله كل لما نروح **محطة (node)** اقوله ها وصلنا؟ لا لسا ها وصلنا؟  لا لسا ممكن يخلص **المحطات (nodes)** كلها ومنوصلش اصلاََ بس كل لما نعدي **محطة (node)** لازم يسجلها ف **المحطات الى عدينا عليها (explored set)** علشان منرجعلهاش تاني وممكن ربنا يكرم ونوصل واقوله بس بس نزلني هنا يا الي منك لله واشوف بقى **المحطة الى فيها الشاطئ دي (solution)** بعيده عن **بيتي (initial state)** قد ايه.

#### البحث العميق أولاََ (Depth-First Search)

في الوصف السابق **للسائق(the  frontier)** هناك شئ لم يتم ذكره. ف المرحلة الثانية, أي محطة يجب ان يتم ازالتها؟ هذا الاختيار ليه تأثير قوي على دقة **الحل** و سرعة الوصول إليه. هناك العديد من الطرق للتعامل مع مسألة المحطة التي يجب أخذها في الاعتبار أولاََ.  اثنتان منهما يمكن تمثيلهما من خلال هياكل البيانات  **الكُومة(stack)** البحث العميق اولاََ (Depth-First Search) و **الصف (queue)** البحث بالعرض اولاََ  (_breadth-first search_)  [وهذا رسم كرتوني لطيف يعرض الفرق بين الأثنين](https://www.youtube.com/watch?v=2wM6_PuBIxY)


سنبدأ بنهج البحث العميق أولاََ (_DFS_).

خوارزمية البحث العميق أولاََ تستنفد كل طريق على حدى قبل محاولة اتخاذ طريق مختلف في هذه الحالات يتم التعامل مع **السائق** على أنه **كُومة (stack)** من البيانات. العبارة التي يجب انا تتذكرها هنا **"أخر الواصلين هيكون أول الخارجين (last-in first-out)"** بعد اضافة المحطات الى السائق أول محطة يتم إزالتها وأخذها بالإعتبار هي أخر محطة سيتم إضافتها. هذا سيسبب خوارزمية بحث تأخذ أول طريق يقابلها إلى أقصى عمق ممكن بينما تترك باقي الأتجاهات الأخرى لاحقاََ

(مثال من خارج المحاضرة: تخيل انك تبحث عن مفاتيحك بطريقة **البحث العميق اولاََ** لو قمت بإختيار البحث في بنطالك هتقوم بالبحث في كل جيب على حدى وتقوم بإخلاء كل جيب والبحث بشكل دقيق ستقوم بإيقاف البحث في بنطالك والبحث في مكان أخر فقط عندما تقوم بفحص جميع الجيوب)

- المميزات:

	-  في أفضل الأحوال هذه الخوارزمية هي الأسرع إذا حالفها الحظ واختارت المسار الصحيح للحل (بالصدفة) في هذه الحالة طريقة البحث العميق أولاََ تأخذ أقل وقت للوصول إلى الحل.

- العيوب:

	-  من الممكن أن تكون طريقة الحل التي تصل اليها ليست الأفضل
	- في أسوء الأحوال ستقوم هذه الخوارزمية بفحص كل الطرق الممكنة قبل الوصول إلى الحل وهذا سيؤدي إلى أخذ أطول وقت ممكن قبل الوصول للحل.

مثال بالكود: 

```Python
#دي الاداة الى هنستخدمها علشان نشيل من قايمة السواق ونرجعها
def remove(self):
#تقوم بإلغاء البحث اذا كان السائق ليس لديه أي اتجاهات متاحة ليأخذها هذا يعني أنه ليس هناك حل
	if self.empty():
		raise Exception("empty frontier")
	else:

    # حفظ أخر محطة بالقائمة (أخر محطة تم اضافتها)
		node = self.frontier[-1]

# حفظ كل المحطات في القائمة باستثناء المحطة الأخيرة (أي إزالة المحطة الأخيرة)

		self.frontier = self.frontier[:-1]
		return node
```

#### البحث  حسب العرض أولاََ (Breadth-First Search)

العكس من **البحث العميق اولاََ (DFS)** هو **البحث بالعرض اولاََ (BFS)** 

خوارزمية **البحث بالعرض اولاََ (BFS)** ستتبع عدة اتجاهات في نفس الوقت وتأخذ خطوة في كل اتجاه ممكن قبل ان تأخذ الخطوه الثانية في كل اتجاه وفي هذه الحالة يتم التعامل مع **السائق (the frontier)** على أنه **صف من البيانات (a queue of data)** العبارة التي يجب انا تتذكرها هنا **"أول الواصلين هيكون أول الخارجين (first-in first-out)"** وفي هذه الحالة كل المحطات الجديدة تضاف الى صف ويتم التعامل مع المحطات على حسب أياََ منهم تمت اضافته اولاََ (أول الواصلين هو الي هياخد خدمته الأول) وهذا يؤدي الى خوارزمية بحث تأخذ خطوه في كل اتجاه ممكن قبل أخذ خطوه ثانية في اي اتجاه أخر

(مثال من خارج المحاضرة: فلنفترض أنك تبحث عن مفاتيحك في هذه الحالة اذا بدأت ببنطالك ستنظر بالجيب الأيمن وبعد ذلك بدلاََ من فحص الجيب الأيسر ستذهب لتلقى نظره على درج المكتب وبعد ذلك على الطاولة وهكذا في كل مكان ممكن ان تفكر به حتى تستنفد كل الأماكن فتعود لبنطالك لتفحص الجيب التالي)

- مميزات:

	-  هذه الخوارزمية من المؤكد ان تجد **أفضل حل ممكن(optimal solution)** 

- عيوب:

	-  إحتمال بنسبة مؤكدة ان تستغرق هذه الخوارزمية وقت أطول من الحد الأدنى
	- في أسوء الأحوال تستغرق هذه الخوارزمية أطول وقت ممكن


مثال بالكود: 

```python
def remove(self):
	if self.empty():
		raise Exception("empty frontier")
	else:
	#حفظ أول محطة في القائمة (الى هي أول محطة تمت اضافتها)
		node = self.frontier[0]
	# حفظ كل المحطات في القائمة باستثناء المحطة الأولى (أي إزالة المحطة الأولى)
		self.frontier = self.frontier[1:]
		return node
```



#### البحث بجشع عن الأفضل أولاََ (Greedy Best-First Search)

البحث حسب العرض اولاََ و البحث العميق أولاََ كلاهما خوارزميات **غير مُرشَدة (uninformed)** لأن هذه الخوارزميات لا **تستخدم** أي معلومات عن المشكلة **مسبقًا**، بل تعتمد فقط على استكشافها الخاص. ولكن في اغلب الأحيان تكون بعض المعلومات عن المشكلة متاحة بالفعل. على سبيل المثال عندما يكون بشري بمتاهه ويصل الى تقاطع يستطيع البشري رؤية أي طريق يؤدي الى الحل وأي طريق لا يؤدي اليه الذكاء الاصطناعي يمكنه عمل نفس الشئ. نوع من الخوارزميات التي تاخذ في الاعتبار المعلومات الإضافية لتحسين ادئها وهذا يسمى خوارزمية بحث  **مُرشَدة (informed)** 

**البحث بجشع عن الأفضل أولاََ  (Greedy best-first search)** يوسع المحطة الأقرب الى الهدف كما يتم تحديدها عبر **دالة إرشادية (heuristic function)** _h(n)_ . كما هو واضح من اسمها الدالة تقدر مدى قرب الهدف من المحطة التالية ولكن من الممكن ان تخطئ. تعتمد كفاءة خوارزمية البحث بجشع عن الأفضل على مدى جودة الدالة الارشادية. على سبيل المثال في متاهه ممكن لخوارزمية ان تستخدم دالة ارشادية تعتمد على مسافة مانهاتن بين المحطات الممكنة والهدف. تقوم مسافة مانهاتن بتجاهل الحوائط وإحصاء عدد الخطوات التي نأخذها سواء أعلى, أسفل أو الجانبين للوصول من مكاناََ ما الى الهدف وهذا شئ يسهل تقديره بناءاََ على  (x, y) احداثيات كلاََ الموقع الحالي وموقع الهدف


![Manhattan Distance](https://cs50.harvard.edu/ai/notes/0/manhattandistance.png)

مسافة مانهاتن

مع ذلك من المهم التأكيد على انه مع أي دالة إرشادية من الممكن ان تخطأ و تقود الخوارزمية إلى طريق أبطأ مما كانت ستسلكه لولا ذلك ومن الممكن انا تقدم خوارزمية بحث غير مُرشَدة حل أفضل ولكن احتمالية تحقيقها لذلك أقل من الخوارزمية المُرشَدة.

#### قصة صغيرة خارج محتوى الكورس:

عندما قام بيتر هارت، ونيلز نيلسون، وبرترام رافائيل مصممي خوارزمية **(* A)**  بنشرها عام 1968 كانوا يقارنوا استراتيجيات بحث مختلفة وقدموا **(* A)** على أنها أنسب **خوارزمية للبحث عن الأفضل أولاََ (best-first search algorithm)** تم استخدام (“A”) كاختصار لكلمة خوارزمية بالانجليزية متبوعة بكلمة الدرجة او الفئة **algorithm class** اما بالنسبة ل علامة النجمة تؤشر الى ان هذه الخوارزمية هي **الأمثل او المميزة (optimal**, or **special**) الأن ممكن ناخد اسم (الفئة الأمثل او الفئة المميزة) كعنوان لهذه الخوارزمية ولكن عندما نقول نقول بالعربية كلاس A دائما ترمز للصف الأول او الفئة الاولى لذلك اخترت عنوان "**A* Search**" بالعربية سيكون **خوارزمية بحث الفئة الأولى** وهذا الأسم الذي سنكمل به شرحنا يلا بينا


#### خوارزمية بحث الفئة الأولى (A* Search)

هي تطورت من خوارزمية **البحث بجشع عن الأفضل أولاََ (Greedy Best-First Search)** لأن **خوارزمية بحث الفئة الأولى (A* Search)** لا تضع بإعتبارها  _h(n)_ التكلفة التقديرية المتبقية للوصول إلى الهدف فقط بل أيضاََ التكلفة المتراكمة حتى المكان الحالي بدمج هاتين القيمتين الخوارزمية لديها طرق أدق لتحديد تكلفة الحل و  تحسين اختيارتها اثناء العملية. الخوارزمية تراقب (تكلفة الطريق حتى الأن + التكلفة المُقدَّرة للوصول للهدف) وعندما تتخطى التكلفة المُقدَّرة من خيار سابق ستقوم الخوارزمية بترك الطريق الحالي والعودة للخيار الأسبق وبالتالي تمنع نفسها من إتخاذ طريق طويل غير فعال تم وضع عليه علامة _h(n)_ بشكل خاطئ على أنه الأفضل .

و لكن مجدداََ بما أن هذه الخوارزمية أيضاََ تعتمد على دالة إرشادية وبذلك فهي جيدة على حسب جودة الدالة الإرشادية التي تستخدمها. ومن الممكن ان اتكون في بعض الأحيان أقل كفاءة من **البحث بجشع عن الأفضل أولاََ (Greedy Best-First Search)** او حتى أقل من الخوارزميات **الغير مُرشَدة (uninformed)**. لكي تكون **خوارزمية بحث الفئة الأولى (A* Search)** الأفضل يجب تكون  **الدالة إرشادية (heuristic function)** _h(n)_ كالتالي:

1. مقبول ولا يبالغ في تقدير التكلفة الحقيقية أبداََ
2. ثابت بحيث ان تكون التكلفة المُقدَّرة الى الهدف من محطة جديدة بالأضافة الى تكلفة الأنتقال إليها من المحطة السابقة أكبر من أو يساوي التكلفة المُقدَّرة للهدف من المحطة السابقة لنضعها في صيغة معادلة _h(n)_ ثابت اذا كان لكل محطة _n_ و محطة تابعة _’n_ مع تكلفة الخطوة "c"
   وهذه المعادلة h(n) ≤ h(n’) + c

---
## 🎯 هدفنا: نفهم المعادلة دي **h(n) ≤ c(n, n′) + h(n′)**


**تخيل إنك مسافر إلى القاهرة، وبتستخدم GPS كـ خريطة تقديرية.**


- أنت واقف في مدينة اسمها "النقطة ن" (n).
    
- عايز تروح القاهرة.
    
- عندك GPS بيعطيك **تقدير** للمسافة الباقية لكل نقطة.

### 💡 المفاهيم في التشبيه:

| المفهوم    | التشبيه الواقعي                                  |
| ---------- | ------------------------------------------------ |
| `h(n)`     | المسافة اللي GPS بيقولها من مكانك الحالي للقاهرة |
| `c(n, n′)` | المسافة الحقيقية بينك وبين المدينة اللي بعدك     |
| `h(n′)`    | تقدير GPS من المدينة التالية للقاهرة             |

---

## 📐 المعادلة بتقول إيه بقى؟

> تقدير المسافة من مكانك الحالي للقاهرة  
> لازم يكون أصغر من أو يساوي
> **المسافة الحقيقية للمدينة اللي بعدك**  
> وضيف عليهم  
> **تقدير GPS من المدينة دي للقاهرة**

### ✅ مثال واضح:

- أنت في طنطا
    
- و GPS بيقول  : المسافة للقاهرة = **90 كم** → هذا هو `h(n)`
    
- المدينة اللي بعدك هي بنها، والمسافة من طنطا لبنها = **40 كم** → هذا هو `c(n, n')`
    
- وGPS من بنها للقاهرة = **50 كم** → هذا هو `h(n')`
    

> الآن نطبق المعادلة `h(n) ≤ c(n, n') + h(n')`  
> `90 ≤ 40 + 50`  
> `90 ≤ 90` ✅ تمام!

الـ GPS هنا بيتصرف بذكاء وثبات، ما بيغيرش رأيه فجأة.

---

### ❌ أما لو حصل العكس:

لو GPS قال:

- من طنطا للقاهرة: 90 كم
    
- ومن بنها للقاهرة: 30 كم فقط
    

يبقى:

> `90 ≤ 40 + 30`  
> `90 ≤ 70` ❌ غلط

يعني كأن GPS بيقولك:  
"لما توصل بنها، القاهرة فجأة قربت بطريقة غريبة!"  
وده بيخربط الحسابات، ومش بيحصل في دالة إرشادية ثابتة (consistent heuristic).

---
## 🔁 خلاصة التشبيه:

> **الـدالة إرشادية الثابتة زي GPS محترم، بيقلل المسافة خطوة خطوة، مش فجأة يقصر الطريق بشكل غريب.**

هو بيقولك:

> "أنا مش متأكد 100%، بس كل ما تقرب خطوة، أنا متوقع الطريق يفضل يقل بشكل طبيعي، مش فجأة يبقى أسهل."


#### **البحث التنافسي (Adversarial Search)**

في السابق، كنا نتحدث عن خوارزميات هدفها إيجاد إجابة لسؤال معين. أما في البحث التنافسي، فالخوارزمية تواجه خصمًا يحاول تحقيق هدف معاكس. وغالبًا ما يُستخدم هذا النوع من البحث في الألعاب، مثل لعبة (Tic Tac Toe) المعروفة ب X - O.

**خوارزمية Minimax**

Minimax هي خوارزمية في مجال البحث التنافسي، تعتمد على تمثيل النتائج كالتالي:

- الفوز لأحد اللاعبين يُمثّل بـ +1
    
- الخسارة بـ -1
    
- التعادل بـ 0
    

اللاعب الذي يحاول الفوز (Maximizer) يسعى للوصول لأعلى قيمة، أما الخصم (Minimizer) فيسعى للوصول لأقل قيمة.

**تمثيل ذكاء اصطناعي للعبة Tic Tac Toe**

- S₀: الحالة الابتدائية (لوحة فارغة 3x3)
    
- Players(s): دالة تُحدد مَن اللاعب في الحالة s (X أو O)
    
- Actions(s): دالة تُرجع الحركات القانونية (الخانات الفارغة في اللوحة)
    
- Result(s, a): دالة تُرجع الحالة الناتجة من تنفيذ الحركة a على الحالة s
    
- Terminal(s): دالة تتحقق إذا كانت اللعبة انتهت (فوز أو تعادل)
    
- Utility(s): دالة تُعطي قيمة نهائية للحالة: 1 أو 0 أو -1
    

**كيف تعمل الخوارزمية؟**

الخوارزمية تحاكي كل احتمالات اللعب من الحالة الحالية حتى نهاية اللعبة. كل حالة نهائية تُقيَّم بـ -1 أو 0 أو +1.

بما أن الخوارزمية تعرف مَن الدور عليه، فإنها تختار الحركة التي تؤدي إلى أفضل نتيجة بالنسبة للاعب الحالي (أعلى قيمة للمُعظِّم أو أقل قيمة للمُقلِّل)، عبر التبديل بين الأدوار بشكل تكراري.

**فكرة التكرار:**

- اللاعب المعظِّم يسأل: "لو نفذت هذه الحركة، ماذا سيفعل الخصم؟"
    
- ثم يفكر بما سيفعله الخصم، الذي بدوره يتساءل: "إذا قمت أنا بحركة، ماذا سيفعل اللاعب الأول؟"
    

وهكذا، كل لاعب يتوقع أفضل ما يمكن أن يفعله خصمه، حتى يصل إلى الحالات النهائية، ويُقيِّمها ثم يختار الأفضل.

**الرمز التوضيحي (Pseudo-code):**

```
Function Max-Value(state):
    v = -∞
    if Terminal(state):
        return Utility(state)
    for action in Actions(state):
        v = Max(v, Min-Value(Result(state, action)))
    return v

Function Min-Value(state):
    v = ∞
    if Terminal(state):
        return Utility(state)
    for action in Actions(state):
        v = Min(v, Max-Value(Result(state, action)))
    return v
```

**التقليم (Alpha-Beta Pruning)**

هي طريقة لتحسين أداء Minimax عن طريق تجاهل الفروع التي من الواضح أنها لن تكون مفيدة. إذا وُجد خيار بالفعل له نتيجة جيدة، وأثناء فحص خيار آخر ظهر أنه سيعطي نتيجة أسوأ، فلا داعي لإكمال فحصه.

**مثال توضيحي:** إذا كان لدى اللاعب المُعظِّم ثلاث خيارات، وأول خيار أعطى قيمة 4، وبدأنا نفحص الخيار الثاني ولاحظنا أن أحد الخيارات التي سيتخذها الخصم بعده تعطي قيمة 3، نوقف فورًا. لأن الخصم سيختار 3، وهي أقل من 4، إذًا هذا الخيار أسوأ من الأول.

**Minimax بعمق محدود (Depth-Limited Minimax)**

عدد حالات لعبة إكس-أو محدود ويمكن حساب كل الاحتمالات. أما في الشطرنج، عدد الحالات الممكنة هائل. لذلك لا يمكننا توليد كل الحالات حتى النهاية.

في Minimax بعمق محدود، يتم تحديد عدد معين من الحركات فقط ثم التوقف. في هذه الحالة، لا نصل لنهاية اللعبة، لذلك نستخدم "دالة تقييم (Evaluation Function)" تقدّر مدى فائدة الوضع الحالي للاعب.

مثال: في الشطرنج، يمكن لدالة التقييم أن تعتمد على عدد القطع المتبقية لكل لاعب ومواقعها على اللوحة لتقدير من في وضع أفضل.

كلما كانت دالة التقييم أدق، كانت قرارات Minimax أفضل.